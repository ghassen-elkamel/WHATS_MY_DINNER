# -*- coding: utf-8 -*-
"""whats-my_dinner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11px8LIavj_sGjt5jWUddL4E6MUJq8ftm

### connecting to kaggle to import the dataset
"""

from google.colab import drive
drive.mount("/content/gdrive", force_remount=True)

!pip install kaggle

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/AI/

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/MyDrive/AI/"

"""## downloading the dataset"""

!kaggle datasets download -d paultimothymooney/recipenlg

!unzip recipenlg.zip

"""## reading the dataset"""

import pandas as pd 
import numpy as np
import re
import nltk
dataset= pd.read_csv('RecipeNLG_dataset.csv',on_bad_lines='skip')

dataset[['title','directions','NER']].head(100)

"""## cleaning the data"""

import string
def remove_penctuation(txt):
    txt_nopenct="".join([c for c in txt if c not in string.punctuation])
    return  txt_nopenct

dataset['NER_clean']=dataset['NER'].apply(lambda x: remove_penctuation(x))

"""## vectorizing the data """

from sklearn.feature_extraction.text import TfidfVectorizer
dataset_sample=dataset[0:]
tfidf=TfidfVectorizer()
x=tfidf.fit_transform(dataset_sample['NER_clean'])
print(x.shape)
print(x)

from ctypes import sizeof
from numpy.ma.core import transpose
df=pd.DataFrame(x.toarray(),columns=tfidf.get_feature_names_out())
d=tfidf.get_feature_names_out()

df.head()
arr=df.to_numpy()

#g=tfidf.get_feature_names_out()[13]
print(arr)

"""## testing """

def get_recipes(f,arr):

  c=0
  q=tfidf.get_feature_names_out()
  print (q)
  for i in range(1717):
    if q[i]==f :
     c=i

  t = []
  d={}
  a=0
  for j in range (100):
   v=arr[j][c]
   if v>0.0:
      #print(j)
    t.append (j)
    d[v]=j
    a=a+1
  t.sort(reverse=True)
 # print(d)
  for i in range(a):
    key=t[i]
    print("title:")
    print((dataset_sample['title'][key]))
    print("\n")
    print("gradients:\n")
    print((dataset_sample['NER_clean'][[key]]))
    print("steps:\n")
    print((dataset_sample['directions'][[key]]))

element=input("give your element please: \n")
get_recipes(element,arr)

"""## saving the necessairy files to run our model"""

from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
import pickle
from numpy import asarray
from numpy import savetxt
savetxt('data.csv', arr, delimiter=',')

import numpy as geek
q=tfidf.get_feature_names_out()


q1=geek.array_str(q)

type(q1)
text_file = open("gradients_data.txt", "w")
 
text_file.write(q1)
 

text_file.close()

import sys
import numpy
numpy.set_printoptions(threshold=sys.maxsize)
q1=geek.array_str(q)

text_file = open("gradients_data.txt", "w")
q1=remove_penctuation(q1) 
print(q1)

text_file.write(q1)
 
text_file.close()

xd = pd.DataFrame(dataset_sample, columns= ['title','directions','NER'])
df.to_csv (r'data2.csv', index = False, header=True)